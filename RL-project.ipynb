{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  *Develop an agent that can achieve a specific goal and sub-goal in a maze 10X10 based on RL algorithms.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries to create the maze and give our agent the ability to randomly making choices\n",
    "\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemetation of the maze 10X10 as indicated in the assignment. \n",
    "\n",
    "# 1 represents the walls (unpassable)\n",
    "# 0 represents an open path (passable)\n",
    "# S marks the starting point of the agent\n",
    "# G marks the sub-goal the agent should reach before continuing\n",
    "# E marks the end goal\n",
    "\n",
    "maze = np.array([[1,1,1,1,1,1,1,1,1,1],\n",
    "                 [1,'S',1,0,0,0,1,0,0,1],\n",
    "                 [1,0,1,0,1,0,1,0,1,1],\n",
    "                 [1,0,0,0,1,0,0,0,0,1],\n",
    "                 [1,1,1,0,1,1,1,1,0,1],\n",
    "                 [1,0,1,'G',0,0,0,1,0,1],\n",
    "                 [1,0,0,0,1,1,0,0,0,1],\n",
    "                 [1,1,1,0,1,0,1,1,0,1],\n",
    "                 [1,0,0,0,0,0,1,'E',0,1],\n",
    "                 [1,1,1,1,1,1,1,1,1,1]], dtype=object)\n",
    "\n",
    "\n",
    "\n",
    "# Implementatio of the Q-Table\n",
    "# Considering the maze above, and the Q-learning algorithm, we need to initiate\n",
    "# the Q-table. The Q-table include all possible states-actions pairs and their corresponing Q-values.\n",
    "\n",
    "q_table = np.zeros((10,10,4))   # each states have 4 possible actions (up, down, left, right)\n",
    "actions = ['up', 'down', 'left', 'right']\n",
    "\n",
    "\n",
    "# Implementation of the reward system\n",
    "\n",
    "reward_sub_goal = 10\n",
    "reward_end_goal = 50\n",
    "penalty = -1    \n",
    "\n",
    "# Implementation of the agent's interactions with the environment, the way the agent moves in the maze\n",
    "# and the way penalties and rewards are given to the agent.\n",
    "\n",
    "def moves(state, action):\n",
    "    row, col = state\n",
    "\n",
    "    if action == 'up':\n",
    "        next_state = (row - 1, col)\n",
    "    elif action == 'down':\n",
    "        next_state = (row + 1, col)\n",
    "    elif action == 'left':\n",
    "        next_state = (row, col - 1)\n",
    "    elif action == 'right':\n",
    "        next_state = (row, col + 1)\n",
    "    else:\n",
    "        next_state = state\n",
    "\n",
    "# Check if the next state is a wall or out of the maze\n",
    "    if next_state[0] >= 0 and next_state[0] < 10 and next_state[1] >= 0 and next_state[1] < 10:\n",
    "        if maze[next_state] != 1:\n",
    "            if next_state == (5,3):\n",
    "                return next_state, reward_sub_goal, False   #Sub-goal reached \n",
    "            elif next_state == (8,7):\n",
    "                return next_state, reward_end_goal, True    #End-goal reached\n",
    "            else:\n",
    "                return next_state, penalty, False           #No goal reached, keep searching\n",
    "        else:\n",
    "            return state, penalty, False                    #Hit a wall, stay in the same state\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Implementation of the starting funtion, in order to restart the agent's position in the maze\n",
    "# at the end of each episode.\n",
    "\n",
    "def restarting():\n",
    "    return start_position"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
